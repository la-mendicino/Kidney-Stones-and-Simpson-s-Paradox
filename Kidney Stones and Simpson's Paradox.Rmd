---
title: "Kidney Stones and Simpson's Paradox"
author: "Lucas Mendicino"
date: "1/28/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


In 1986, a group of urologists in London published a research paper in The British Medical Journal that compared the effectiveness of two different methods to remove kidney stones. Treatment A was open surgery (invasive), and treatment B was percutaneous nephrolithotomy (less invasive). When they looked at the results from 700 patients, treatment B had a higher success rate. However, when they only looked at the subgroup of patients different kidney stone sizes, treatment A had a better success rate. This known statistical phenomenon is called Simponâ€™s paradox. Simpon's paradox occurs when trends appear in subgroups but disappear or reverse when subgroups are combined.



```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(broom)
library(stats)
```

```{r}
kidney <- read_csv("~/Desktop/kidney.csv")
kidney <- kidney[-1]
head(kidney)
```

The data contains three columns: treatment (A or B), stone_size (large or small) and success (0 = Failure or 1 = Success). To start, we want to know which treatment had a higher success rate regardless of stone size. Let's create a table with the number of successes and frequency of success by each treatment using the tidyverse syntax.


Let's calculate the number and frequency of success and failure of each treatment

```{r}
kidney %>% 
  group_by(treatment, success) %>%
  summarise(N = n()) %>%
  mutate(Freq = round(N/sum(N),3))
```

From the treatment and success rate descriptive table, we saw that treatment B performed better on average compared to treatment A (82% vs. 78% success rate). Now, let's consider stone size and see what happens. We are going to stratify the data into small vs. large stone subcategories and compute the same success count and rate by treatment like we did in the previous task.


Let's calculate the number and frequency of sucess and failure by stone size for each treatment

```{r}
summary <- kidney %>%
  group_by(treatment, stone_size, success) %>%
  summarise(N = n()) %>%
  mutate(Freq = round(N/sum(N), 3))

print(summary)
```

When stratified by stone size, treatment A had better results for both large and small stones compared to treatment B (i.e., 73% and 93% v.s. 69% and 87%). Sometimes a plot is a more efficient way to communicate hidden numerical information in the data. In this task, we are going to apply a plotting technique to reveal the hidden information.



```{r}
ggplot(summary, aes(x = treatment, y = N)) + geom_bar(aes(fill = stone_size), stat = 'identity')
```


From the bar plot, we noticed an unbalanced distribution of kidney stone sizes in the two treatment options. Large kidney stone cases tended to be in treatment A, while small kidney stone cases tended to be in treatment B. Can we confirm this hypothesis with statistical testing?

Let's analyze the association between stone size (i.e., case severity) and treatment assignment using a statistical test called Chi-squared. The Chi-squared test is appropriate to test associations between two categorical variables. This test result, together with the common knowledge that a more severe case would be more likely to fail regardless of treatment, will shed light on the root cause of the paradox.


```{r}
trt_chisq <- chisq.test(kidney$treatment, kidney$stone_size)

tidy(trt_chisq)
```

We are confident that stone size/case severity is indeed the confounding variable in this study of kidney stone treatment and success rate. The good news is that there are ways to get rid of the effect of the lurking variable.

Let's use multiple logistic regression to remove the unwanted effect of stone size.


```{r}
model <- glm(data = kidney, success ~ treatment + stone_size, family = "binomial")

tidy(model)
```

We successfully fit a multiple logistic regression and pulled out the model coefficient estimates! Typically (and arbitrarily), P-values below 0.05 indicate statistical significance. Another way to examine whether a significant relationship exists or not is to look at the 95% confidence interval (CI) of the estimate. In our example, we are testing to see:

- if the effect of a small stone is the same as a big stone, and
- if treatment A is as effective as treatment B.

If the 95% CI for the coefficient estimates cover zero, we cannot conclude that one is different from the other. Otherwise, there is a significant effect.


```{r}
tidy_model <-tidy(model)

tidy_model %>%
  ggplot(aes(x = term, y = estimate)) + 
  geom_pointrange(aes(ymin = estimate - 1.96 * std.error, 
                      ymax = estimate + 1.96 * std.error)) +
  geom_hline(yintercept = 0)
```

Based on the coefficient estimate plot and the model output table, there is enough information to generate insights about the study. Is treatment A superior to B after taking into account the effect of stone size/severity level?

Everything is in the output table from the regression model. Recall, a coefficient represents the effect size of the specific model term. A positive coefficient means that the term is positively related to the outcome. For categorical predictors, the coefficient is the effect on the outcome relative to the reference category. In our study, stone size large and treatment A are the reference categories.


Is small stone more likely to be a success after controlling for treatment option effect? Yes

Is treatment A significantly better than B? No














